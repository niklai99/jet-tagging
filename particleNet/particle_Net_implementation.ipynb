{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm.notebook import tqdm # this module is useful to plot progress bars\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_df_path = '../data/particle_df.csv'\n",
    "particle_preproc_df_path = '../data/particle_df_preprocessed.csv'\n",
    "par_pre_df = pd.read_csv(particle_preproc_df_path)\n",
    "par_df = pd.read_csv(particle_df_path)\n",
    "par_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataset(Dataset):\n",
    "    # The ParticleDataset class inherits the Dataset class and implements the __init__, __len__, and __getitem__ methods\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        # Initializing the ParticleDataset object.\n",
    "        # \"path\" is the path to the csv file containing the particle data.\n",
    "        # \"transform\" is an optional argument that specifies the transformations to be applied to the data.\n",
    "\n",
    "        # Read the csv file into a Pandas DataFrame.\n",
    "        self.x = pd.read_csv(path)\n",
    "\n",
    "        # Put the coordinates eta and phi as the first two features\n",
    "        self.x = self.x.reindex(\n",
    "            columns=[\"particlePolarPy\", \"particlePhi\"]\n",
    "            + [\n",
    "                col\n",
    "                for col in self.x.columns\n",
    "                if col not in [\"particlePolarPy\", \"particlePhi\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the \"transform\" argument.\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of particles in the dataset.\n",
    "        \"\"\"\n",
    "        # Return the number of rows in the DataFrame (i.e., the number of particles).\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the particles with jetID = idx.\n",
    "        \"\"\"\n",
    "        # Get the rows in the DataFrame that have a \"jetID\" column equal to \"idx\".\n",
    "        x = self.x[self.x.jetID==idx].to_numpy()\n",
    "        \n",
    "        # If \"transform\" was specified, apply it to the data.\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        # Return the transformed data.\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Compose object that applies the \"ToTensor\" transformation.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Create a ParticleDataset object using the csv file located at \"particle_df_path\" and the \"train_transform\" transformations.\n",
    "train_data = ParticleDataset(particle_df_path, train_transform)\n",
    "\n",
    "# Access the first element in the dataset to get its shape.\n",
    "train_data[1].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom collate only for a dataset with jets composed by a different number of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    A custom collate function that can handle different shape tensors.\n",
    "    The default collate function provided by PyTorch's DataLoader assumes that all tensors in a batch have the same shape. \n",
    "    However, in our case, each \"datum\" is a set of particles that compose a jet and the number of particles composing a jet is not fixed. \n",
    "    Therefore, each tensor representing a jet has a different shape.\n",
    "\n",
    "    To handle this scenario, we need to override the collate function to be able to stack the tensors into a batch. \n",
    "    This function first determines the maximum number of particles among all jets in the batch. \n",
    "    Then, it pads all tensors with zeros to make sure they have the same shape. \n",
    "    Finally, it stacks the tensors along the batch dimension to return the padded data and original lengths.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the max number of particles among all the jets in the batch\n",
    "    n_part_max = max(x.shape[1] for x in batch)\n",
    "\n",
    "    # Pad all the tensors with zeros so they have the same shape\n",
    "    data = []\n",
    "    lengths = []\n",
    "    for x in batch:\n",
    "        n_part = x.shape[1]\n",
    "        data.append(torch.cat([x, torch.zeros(1, n_part_max - n_part, 16)], dim=1).squeeze())\n",
    "        lengths.append(n_part)\n",
    "\n",
    "    # Stack the tensors along the batch dimension\n",
    "    data = torch.stack(data)\n",
    "\n",
    "    # Return the padded data, original lengths, and target labels\n",
    "    return data, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size       = 10\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, collate_fn=custom_collate)\n",
    "\n",
    "# loop over the dataloader to get the data in batches\n",
    "i=0\n",
    "for batch, original_length in train_dataloader:\n",
    "    print(batch.shape, original_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Edge Convolution Block ###########\n",
    "# The root block of our DNN.\n",
    "# Initialized by:\n",
    "#   - d     the number of features\n",
    "#   - k     number of nearest neighbours to consider in the concolution\n",
    "#   - C     a list-like or an int with the number of neurons of the three linear layers\n",
    "#   - aggr  the aggregation function, must be symmetric\n",
    "\n",
    "class EdgeConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, k, C, aggr=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if type(C) == int:\n",
    "            self.C = [C]*3\n",
    "        else:\n",
    "            self.C = C\n",
    "        \n",
    "        self.k = k\n",
    "\n",
    "        if aggr is None:\n",
    "            self.aggr = torch.mean\n",
    "        else:\n",
    "            self.aggr = aggr\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "\n",
    "        ### Shortcut path\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = d, out_channels = self.C[-1], kernel_size = 1, stride = 1),\n",
    "            nn.BatchNorm1d(self.C[-1])\n",
    "        )\n",
    "\n",
    "        ### Linear section, approximation of a MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(2*d, self.C[0], 1, 1),\n",
    "            nn.BatchNorm2d(self.C[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.C[0], self.C[1], 1, 1),\n",
    "            nn.BatchNorm2d(self.C[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.C[1], self.C[2], 1, 1),\n",
    "            nn.BatchNorm2d(self.C[2]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def kNN(self, x):\n",
    "        \"\"\"input: single jet data\n",
    "            output: tensor with shape [B, n, k, d] where d are the features of the knn particles\"\"\"\n",
    "        # expand the input tensor s.t. x_knn.shape = [B, n, n, d]\n",
    "        x_knn = x.unsqueeze(1).expand(-1, x.shape[1], -1, -1)\n",
    "\n",
    "        # calculate both delta_phi and delta_eta\n",
    "        delta_phieta = x_knn[:, :, :, :2] - x_knn[:, :, :, :2].transpose(1, 2)\n",
    "\n",
    "        # calculate distances and sort them in ascending order, keep only the indeces\n",
    "        _, indeces = torch.sqrt(torch.sum(delta_phieta**2, 3)**0.5).sort(dim=2, stable=True)\n",
    "\n",
    "        # keep the indeces of k nearest neighbours and use them to sort and cut the initial tensor\n",
    "        knn = indeces[:,:,:self.k]\n",
    "        x_knn = torch.gather(x_knn, 2, knn.unsqueeze(-1).expand(-1, -1, -1, x_knn.shape[-1]))\n",
    "\n",
    "        del delta_phieta, indeces, knn, _\n",
    "\n",
    "        return x_knn    # x_knn.shape = [B, n, k, d]\n",
    "\n",
    "    \n",
    "    def linear_aggregate(self, x):\n",
    "\n",
    "        # accepts as input [B, d, n, k]\n",
    "\n",
    "        # take the features of the particle and repeat them on the third axis\n",
    "        p_feat = x[:, :, :, 0].unsqueeze(3).expand(-1, -1, -1, self.k)\n",
    "\n",
    "        # now we can calculate knn features for each particle as a simple difference\n",
    "        knn_feat = x - p_feat\n",
    "\n",
    "        print('p_feat:', p_feat.shape, '\\nknn_feat:', knn_feat.shape)\n",
    "\n",
    "        pairs = torch.concat([p_feat, knn_feat], dim=1)\n",
    "        del p_feat, knn_feat\n",
    "        print(pairs.shape) # expected [B, 2*d, n, k]\n",
    "\n",
    "        mlp_result = self.mlp(pairs)\n",
    "        del pairs\n",
    "\n",
    "        # aggregate\n",
    "        aggr_result = self.aggr(mlp_result, dim=3)\n",
    "\n",
    "        if type(aggr_result) is tuple:\n",
    "            aggr_result = aggr_result[0]\n",
    "        \n",
    "        return aggr_result\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.size = [B, n, d]\n",
    "        # x_knn.size = [B, n, k, d]\n",
    "\n",
    "        x_knn = self.kNN(x).transpose(1, 3).transpose(2, 3)\n",
    "        shortcut = self.shortcut(x.transpose(1, 2))\n",
    "        x = self.linear_aggregate(x_knn)\n",
    "\n",
    "        x = self.act(x + shortcut).transpose(1, 2)\n",
    "        \n",
    "        del x_knn, shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleNet():\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # EDGE CONV PART\n",
    "        self.edge_conv = nn.Sequential(\n",
    "            EdgeConv(d=16, k=10, C=[64,64,64]),\n",
    "            EdgeConv(d=16, k=10, C=[128,128,128]),\n",
    "            EdgeConv(d=16, k=10, C=[256,256,256])) #output shape = [B,n,256]\n",
    "\n",
    "        self.final_part = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1))\n",
    "\n",
    "        # LATENT SPACE PROJECTION\n",
    "        # output size -> dimension of the latent space\n",
    "        self.latent_space = nn.Sequential(\n",
    "            nn.Linear(in_features = 256, out_features = encoded_space_dim),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.edge_conv(x)\n",
    "        y = nn.AvgPool1d(kernel_size=y.shape[1], stride=1)(y.transpose(1,2))\n",
    "        y = self.final_part(y)\n",
    "        y= self.latent_space(y)\n",
    "\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Learing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr = 5e-4 # Learning rate\n",
    "\n",
    "# params_to_optimize = [\n",
    "#     {'params': encoder.parameters()},\n",
    "#     {'params': decoder.parameters()}\n",
    "# ]\n",
    "# optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# # Check if the GPU is available\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(f'Selected device: {device}')\n",
    "\n",
    "# # Move both the encoder and the decoder to the selected device\n",
    "# encoder.to(device)\n",
    "# decoder.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # abbiamo gi√† definito l'optimizer nella cella precedente\n",
    "    \n",
    "    losses = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        \n",
    "        image_batch = image_batch.to(device)\n",
    "        #encode\n",
    "        y_encoder_pred = encoder(image_batch)\n",
    "        #decode\n",
    "        y_decoder_pred = decoder(y_encoder_pred)\n",
    "\n",
    "        loss = loss_fn(y_decoder_pred, image_batch)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    losses = np.mean(losses)\n",
    "    return losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60560e0d6226cb5287d81368c04acd3a7e9c5751a6dd0763b56dc9cf4b259ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
